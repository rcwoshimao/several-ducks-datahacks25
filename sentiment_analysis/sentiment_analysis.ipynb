{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers==4.32.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (4.32.1)\n",
      "Requirement already satisfied: sympy==1.10.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from torch==2.0.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from torch==2.0.1) (4.13.1)\n",
      "Requirement already satisfied: networkx in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from torch==2.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from transformers==4.32.1) (4.67.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from sympy==1.10.1) (1.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.1) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from requests->transformers==4.32.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from requests->transformers==4.32.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from requests->transformers==4.32.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from requests->transformers==4.32.1) (2025.1.31)\n",
      "Requirement already satisfied: pandas in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scipy in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (from scipy) (1.24.4)\n",
      "Requirement already satisfied: numpy==1.24.4 in /Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1 transformers==4.32.1 sympy==1.10.1\n",
    "!pip install pandas matplotlib seaborn\n",
    "!pip install scipy\n",
    "!pip install numpy==1.24.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/ethanarnn/anaconda3/envs/roberta-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentiment(tweet):\n",
    "\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt')\n",
    "\n",
    "    output = model(**encoded_tweet)\n",
    "\n",
    "    scores = softmax(output[0][0].detach().numpy())\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def max_depth(tweet_data):\n",
    "        stack = []\n",
    "\n",
    "        max_length = 0\n",
    "\n",
    "        for tweet in tweet_data['comments']:\n",
    "                stack.append((tweet, 1))\n",
    "\n",
    "        while stack:\n",
    "                tweet, layer = stack.pop()\n",
    "                if len(tweet['replies']) == 0: # raeched the end\n",
    "                        max_length = max(layer, max_length)\n",
    "                else:\n",
    "                        for new_tweet in tweet['replies']:\n",
    "                                stack.append((new_tweet, layer + 1))\n",
    "\n",
    "        return max_length\n",
    "\n",
    "\n",
    "def fan_sentiment(tweet_data):\n",
    "       total_score, total_weight = traverse_comments(tweet_data['comments'], 1)\n",
    "       if total_weight == 0:\n",
    "              return\n",
    "       return total_score / total_weight\n",
    "\n",
    "#find longest chain, count num of posts that have 2 or more direct replies, add neutral and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author_name': 'Agent 1',\n",
       "  'personality': {'Sarcastic': 0.12,\n",
       "   'Anger': -0.85,\n",
       "   'Neuroticism': 0.25,\n",
       "   'Toxcitiy': -0.12,\n",
       "   'Obsession': 0.3,\n",
       "   'Elitism': 0,\n",
       "   'Sycophantic': 0.4,\n",
       "   'Loyalty': 0.9,\n",
       "   'Apathy': 0.0},\n",
       "  'message_id': '1_1',\n",
       "  'comment_text': \"She's literally the best songwriter of our generation. Period.\",\n",
       "  'replies': [{'author_name': 'Agent 2',\n",
       "    'personality': {'Sarcastic': 0.12,\n",
       "     'Anger': -0.85,\n",
       "     'Neuroticism': 0.25,\n",
       "     'Toxcitiy': -0.12,\n",
       "     'Obsession': 0.3,\n",
       "     'Elitism': 0,\n",
       "     'Sycophantic': 0.4,\n",
       "     'Loyalty': 0.9,\n",
       "     'Apathy': 0.0},\n",
       "    'message_id': '2_1',\n",
       "    'comment_text': 'More like the most overrated. Her lyrics are just high school poetry.',\n",
       "    'replies': [{'author_name': 'Agent 3',\n",
       "      'personality': {'Sarcastic': 0.12,\n",
       "       'Anger': -0.85,\n",
       "       'Neuroticism': 0.25,\n",
       "       'Toxcitiy': -0.12,\n",
       "       'Obsession': 0.3,\n",
       "       'Elitism': 0,\n",
       "       'Sycophantic': 0.4,\n",
       "       'Loyalty': 0.9,\n",
       "       'Apathy': 0.0},\n",
       "      'message_id': '3_1',\n",
       "      'comment_text': \"You clearly haven't listened to All Too Well (10 Minute Version).\",\n",
       "      'replies': []},\n",
       "     {'author_name': 'Agent 4',\n",
       "      'personality': {'Sarcastic': 0.12,\n",
       "       'Anger': -0.85,\n",
       "       'Neuroticism': 0.25,\n",
       "       'Toxcitiy': -0.12,\n",
       "       'Obsession': 0.3,\n",
       "       'Elitism': 0,\n",
       "       'Sycophantic': 0.4,\n",
       "       'Loyalty': 0.9,\n",
       "       'Apathy': 0.0},\n",
       "      'message_id': '4_1',\n",
       "      'comment_text': 'Go back to your metal cave and leave us in peace.',\n",
       "      'replies': []}]}]},\n",
       " {'author_name': 'Agent 5',\n",
       "  'personality': {'Sarcastic': 0.12,\n",
       "   'Anger': -0.85,\n",
       "   'Neuroticism': 0.25,\n",
       "   'Toxcitiy': -0.12,\n",
       "   'Obsession': 0.3,\n",
       "   'Elitism': 0,\n",
       "   'Sycophantic': 0.4,\n",
       "   'Loyalty': 0.9,\n",
       "   'Apathy': 0.0},\n",
       "  'message_id': '5_1',\n",
       "  'comment_text': 'Whether you like her or not, her ability to reinvent herself is impressive.',\n",
       "  'replies': [{'author_name': 'Agent 6',\n",
       "    'personality': {'Sarcastic': 0.12,\n",
       "     'Anger': -0.85,\n",
       "     'Neuroticism': 0.25,\n",
       "     'Toxcitiy': -0.12,\n",
       "     'Obsession': 0.3,\n",
       "     'Elitism': 0,\n",
       "     'Sycophantic': 0.4,\n",
       "     'Loyalty': 0.9,\n",
       "     'Apathy': 0.0},\n",
       "    'message_id': '6_1',\n",
       "    'comment_text': \"Or maybe it's just marketing gimmicks lol.\",\n",
       "    'replies': [{'author_name': 'Agent 7',\n",
       "      'personality': {'Sarcastic': 0.12,\n",
       "       'Anger': -0.85,\n",
       "       'Neuroticism': 0.25,\n",
       "       'Toxcitiy': -0.12,\n",
       "       'Obsession': 0.3,\n",
       "       'Elitism': 0,\n",
       "       'Sycophantic': 0.4,\n",
       "       'Loyalty': 0.9,\n",
       "       'Apathy': 0.0},\n",
       "      'message_id': '7_1',\n",
       "      'comment_text': \"Tell me you don't understand artistic evolution without telling me.\",\n",
       "      'replies': []}]}]},\n",
       " {'author_name': 'Agent 8',\n",
       "  'personality': {'Sarcastic': 0.12,\n",
       "   'Anger': -0.85,\n",
       "   'Neuroticism': 0.25,\n",
       "   'Toxcitiy': -0.12,\n",
       "   'Obsession': 0.3,\n",
       "   'Elitism': 0,\n",
       "   'Sycophantic': 0.4,\n",
       "   'Loyalty': 0.9,\n",
       "   'Apathy': 0.0},\n",
       "  'message_id': '8_1',\n",
       "  'comment_text': \"Y'all really acting like she invented music. Calm down.\",\n",
       "  'replies': [{'author_name': 'Agent 9',\n",
       "    'personality': {'Sarcastic': 0.12,\n",
       "     'Anger': -0.85,\n",
       "     'Neuroticism': 0.25,\n",
       "     'Toxcitiy': -0.12,\n",
       "     'Obsession': 0.3,\n",
       "     'Elitism': 0,\n",
       "     'Sycophantic': 0.4,\n",
       "     'Loyalty': 0.9,\n",
       "     'Apathy': 0.0},\n",
       "    'message_id': '9_1',\n",
       "    'comment_text': \"Nobody said that. We're just vibing, let us live.\",\n",
       "    'replies': [{'author_name': 'Agent 8',\n",
       "      'personality': {'Sarcastic': 0.12,\n",
       "       'Anger': -0.85,\n",
       "       'Neuroticism': 0.25,\n",
       "       'Toxcitiy': -0.12,\n",
       "       'Obsession': 0.3,\n",
       "       'Elitism': 0,\n",
       "       'Sycophantic': 0.4,\n",
       "       'Loyalty': 0.9,\n",
       "       'Apathy': 0.0},\n",
       "      'message_id': '8_2',\n",
       "      'comment_text': 'Vibe somewhere else. My feed is full of Swift right now.',\n",
       "      'replies': []},\n",
       "     {'author_name': 'Agent 10',\n",
       "      'personality': {'Sarcastic': 0.12,\n",
       "       'Anger': -0.85,\n",
       "       'Neuroticism': 0.25,\n",
       "       'Toxcitiy': -0.12,\n",
       "       'Obsession': 0.3,\n",
       "       'Elitism': 0,\n",
       "       'Sycophantic': 0.4,\n",
       "       'Loyalty': 0.9,\n",
       "       'Apathy': 0.0},\n",
       "      'message_id': '10_1',\n",
       "      'comment_text': \"Your feed is full of Swift because she's relevant and you're obsessed. 😘\",\n",
       "      'replies': []}]}]},\n",
       " {'author_name': 'Agent 11',\n",
       "  'personality': {'Sarcastic': 0.12,\n",
       "   'Anger': -0.85,\n",
       "   'Neuroticism': 0.25,\n",
       "   'Toxcitiy': -0.12,\n",
       "   'Obsession': 0.3,\n",
       "   'Elitism': 0,\n",
       "   'Sycophantic': 0.4,\n",
       "   'Loyalty': 0.9,\n",
       "   'Apathy': 0.0},\n",
       "  'message_id': '11_1',\n",
       "  'comment_text': \"I don't love her or hate her, but you all need to chill 😂\",\n",
       "  'replies': []}]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)\n",
    "\n",
    "# fan_sentiment(tweet_data)\n",
    "tweet_data['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The deepest layer is 3.\n"
     ]
    }
   ],
   "source": [
    "queue = deque()\n",
    "\n",
    "max_length = 0\n",
    "\n",
    "for tweet in tweet_data['comments']:\n",
    "    queue.appendleft((tweet, 1))\n",
    "\n",
    "while queue:\n",
    "    tweet, layer = queue.pop()\n",
    "    if len(tweet['replies']) == 0: # raeched the end\n",
    "        max_length = max(layer, max_length)\n",
    "    else:\n",
    "        for new_tweet in tweet['replies']:\n",
    "            queue.appendleft((new_tweet, layer + 1))\n",
    "\n",
    "print(f'The deepest layer is {layer}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Agent 47',\n",
       " 'personality': {'Sarcastic': 0.12,\n",
       "  'Anger': -0.85,\n",
       "  'Neuroticism': 0.25,\n",
       "  'Toxcitiy': -0.12,\n",
       "  'Obsession': 0.3,\n",
       "  'Elitism': 0,\n",
       "  'Sycophantic': 0.4,\n",
       "  'Loyalty': 0.9,\n",
       "  'Apathy': 0.0},\n",
       " 'post_text': 'Taylor Swift continues to be one of the most polarizing artists of our time. Some call her a lyrical genius, others... not so much.',\n",
       " 'message_id': 'MAIN',\n",
       " 'comments': []}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "stack = tweet_data['comments']\n",
    "visited = set()\n",
    "responses = []\n",
    "while stack:\n",
    "    tweet = stack.pop()\n",
    "    visited.add(tweet['message_id'])\n",
    "    responses.append(tweet['comment_text'])\n",
    "    for new_tweet in tweet['replies']:\n",
    "        if new_tweet['message_id'] not in visited:\n",
    "            stack.append(new_tweet)\n",
    "\n",
    "print(len(visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't love her or hate her, but you all need to chill 😂\",\n",
       " \"Y'all really acting like she invented music. Calm down.\",\n",
       " \"Nobody said that. We're just vibing, let us live.\",\n",
       " \"Your feed is full of Swift because she's relevant and you're obsessed. 😘\",\n",
       " 'Vibe somewhere else. My feed is full of Swift right now.',\n",
       " 'Whether you like her or not, her ability to reinvent herself is impressive.',\n",
       " \"Or maybe it's just marketing gimmicks lol.\",\n",
       " \"Tell me you don't understand artistic evolution without telling me.\",\n",
       " \"She's literally the best songwriter of our generation. Period.\",\n",
       " 'More like the most overrated. Her lyrics are just high school poetry.',\n",
       " 'Go back to your metal cave and leave us in peace.',\n",
       " \"You clearly haven't listened to All Too Well (10 Minute Version).\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative neutral positive\n"
     ]
    }
   ],
   "source": [
    "print(\"negative\", \"neutral\", \"positive\")\n",
    "senti = []\n",
    "for resp in responses:\n",
    "    senti.append(tweet_sentiment(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.35311177, 0.535969  , 0.11091916], dtype=float32),\n",
       " array([0.6204534 , 0.33567846, 0.04386818], dtype=float32),\n",
       " array([0.04034606, 0.5758512 , 0.38380265], dtype=float32),\n",
       " array([0.02518899, 0.22029097, 0.75452   ], dtype=float32),\n",
       " array([0.40944174, 0.48054302, 0.11001521], dtype=float32),\n",
       " array([0.00429474, 0.08969887, 0.9060064 ], dtype=float32),\n",
       " array([0.30174777, 0.6246345 , 0.07361767], dtype=float32),\n",
       " array([0.65573305, 0.33089852, 0.01336838], dtype=float32),\n",
       " array([0.00200974, 0.0146739 , 0.98331636], dtype=float32),\n",
       " array([0.90713006, 0.08237939, 0.01049064], dtype=float32),\n",
       " array([0.41168505, 0.515554  , 0.07276095], dtype=float32),\n",
       " array([0.6003084 , 0.36756298, 0.0321286 ], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([25.,  7.,  2.,  1.,  6.,  2.,  5.,  2.,  4.,  4.]),\n",
       " array([0.01394084, 0.1111935 , 0.20844616, 0.30569881, 0.40295148,\n",
       "        0.50020415, 0.59745681, 0.69470942, 0.79196209, 0.88921475,\n",
       "        0.98646742]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x = [tup[2] for tup in senti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "stack = tweet_data['comments']\n",
    "visited = set()\n",
    "responses = []\n",
    "while stack:\n",
    "    tweet = stack.pop()\n",
    "    visited.add(tweet['message_id'])\n",
    "    responses.append(tweet['comment_text'])\n",
    "    if 'replies' not in tweet.keys():\n",
    "        continue\n",
    "    for new_tweet in tweet['replies']:\n",
    "        if new_tweet['message_id'] not in visited:\n",
    "            stack.append(new_tweet)\n",
    "\n",
    "print(len(visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['post_text', 'name', 'personality', 'message_id', 'comments'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative neutral positive\n"
     ]
    }
   ],
   "source": [
    "print(\"negative\", \"neutral\", \"positive\")\n",
    "senti = []\n",
    "text = []\n",
    "for resp in responses:\n",
    "    text.append(resp)\n",
    "    senti.append(tweet_sentiment(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This ain't it, chief.\",\n",
       " \"Care to elaborate, or is that all you've got?\",\n",
       " \"No point arguing, you've made up your mind anyway.\",\n",
       " \"Finally someone said it. I thought I was the only one who doesn't worship her.\",\n",
       " 'Oh look, the haters are gathering 🙃.',\n",
       " 'I suspect a lot of the \"overrated\" comments she gets are because her core fanbase is young women. Sadly, anything popular with young women (boy bands, pop stars, etc.) tends to get unfairly trashed as less legitimate. If a dude in a rock band writes about relationships, he\\'s \"deep\", but if Taylor does it, she\\'s \"whiny\" or whatever. There\\'s definitely a double standard in how people judge her and her fans.',\n",
       " \"Or, hear me out: some people just don't like her music. Not everything is about sexism or whatever. I get your point, but sometimes an overrated pop star is just an overrated pop star, regardless of who likes them.\",\n",
       " 'Sure, personal taste plays a role. But it\\'s worth noticing how often \"stuff teenage girls like\" gets labeled overrated or trivial. There might be bias, even if it\\'s subconscious. Food for thought.',\n",
       " 'Have you actually read her lyrics? Songs like \"Blank Space\" are tongue-in-cheek commentary on her media portrayal, and tracks like \"Illicit Affairs\" or \"Tolerate It\" show pretty nuanced storytelling. If you only heard her radio hits, I get thinking she\\'s generic. But dig a bit into her discography and you might find she\\'s a stronger songwriter than you assumed.',\n",
       " 'I actually gave \"Folklore\" a try because people kept saying that. It was better than her older stuff, I\\'ll admit, but I still didn\\'t love it. I can appreciate her talent in storytelling, it’s just not connecting with me personally enough to change my mind that she\\'s overrated for my taste.',\n",
       " 'At least you gave it an honest shot. Fair enough – not every artist is for everyone. Thanks for actually listening before dismissing her entirely.',\n",
       " 'I’m a huge fan, but I cringe when I see some fans act like she invented music or something. She\\'s amazing, but not every single thing she does is a masterpiece. So in a way, I get where the \"overrated\" sentiment comes from, even if I don\\'t love that word. I just wish both her haters and superfans would tone it down a notch.',\n",
       " \"Props to you for being a level-headed fan. It's refreshing.\",\n",
       " \"Totally, she's so overrated *eye roll*. It's not like she's got a shelf full of awards or anything. It's not like she’s broken records in music sales or had critically acclaimed albums, right? Must all be hype. /s\",\n",
       " \"Awards and sales don’t equal quality, though. A lot of mediocre stuff wins awards because it's popular or backed by big labels. So those metrics don't convince me she's some genius.\",\n",
       " \"Fair, awards aren’t everything. But in her case, it's not just popularity contests – she has respect from peers and veteran songwriters too. That says a lot. It's fine if you don't enjoy her stuff, just saying the acclaim didn't come out of nowhere.\",\n",
       " 'Musical taste is subjective. You might not like Taylor Swift, but clearly many people do. Calling her \"overrated\" doesn’t really mean much beyond \"I don’t like her as much as others do.\" She’s talented at what she does, even if it’s not your cup of tea. Maybe just accept that her music isn’t for you and move on.',\n",
       " \"I get it, music is subjective. I just think it's worth discussing why some artists get so huge. I'm not denying she has talent, I just feel it's overblown. But yeah, obviously a lot of people love her, and that's their choice.\",\n",
       " 'She’s the most overrated artist of the century. Period. Her vocals are meh (ever heard her live? cringe), her songwriting is just writing in a diary about exes, and somehow she’s treated like royalty. It’s insane. The media and her fans have put her on a pedestal way higher than she deserves.',\n",
       " \"This is such an exaggerated take. She actually sounds great live now (check her acoustic performances like the NPR Tiny Desk concert). And writing about personal experiences is what almost every songwriter does. You act like she hasn't earned any of her success, which is just false.\",\n",
       " \"I've seen those. Still wasn't impressed. Maybe she's improved a bit, but if you compare her to truly great vocalists, she falls flat. Success doesn’t equal the highest artistic merit, it often equals mass appeal. Big difference.\",\n",
       " \"From an industry standpoint, calling her overrated misses the point that she’s been very savvy in her career. Sure, marketing is part of why she’s huge – but she’s also taken risks (changing genres, re-recording her albums to fight for her masters) that paid off. The music business pushes whoever sells, but she’s had to consistently deliver or she'd have faded like others. Overrated or not, she knows how to stay relevant.\",\n",
       " \"That's true. Love her or not, she's shrewd. A lot of pop stars burn out after a few years, but she’s still on top. Can't just be luck. She turned her name into an empire.\",\n",
       " 'I see a lot of comments attacking her fans as well. Not cool. Enjoying her music doesn’t make us brainless or whatever. There’s nothing wrong with being a fan of a popular artist. You can think what you want about her music, but don’t insult the people who like it. We’re not a \"cult,\" we just connect with her stuff.',\n",
       " 'Some of her stans do go overboard though, you gotta admit. When any criticism is met with intense backlash, it feels cultish from the outside.',\n",
       " \"Every big fandom has a few extreme people. It doesn't mean all of us are like that. Most of us are just normal folks who happen to enjoy her music. Painting all fans as crazy isn’t fair.\",\n",
       " 'Yo, OP, Imma let you finish, but Beyoncé had one of the best videos of all time! *Of all time!* 😏',\n",
       " '2009 called, it wants its meme back. 🙄',\n",
       " \"I've been a fan since her country days, but I kinda see where you're coming from. I love Taylor, but sometimes the praise she gets is over the top. Not every album or song is amazing, and some fans act like she can do no wrong. I still enjoy her music a lot, but yeah, the hype can get a little crazy and make it seem like she's the only artist on the planet.\",\n",
       " \"I felt that way during her pop transition a few years back. But her recent stuff like the indie-folk vibe brought me back. Every artist has ups and downs. The fans might hype everything, but the music still speaks for itself if it's good.\",\n",
       " 'I’ll admit, I used to roll my eyes at her and thought the hype was overblown. But then I actually listened to an entire album (not just the radio singles) and was surprised. Albums like \"Folklore\" and \"Evermore\" really changed my perspective – her storytelling and songwriting there are pretty impressive. I’m not her biggest fan now, but I respect her talent.',\n",
       " \"Glad you gave her a chance. Folklore is what converted a lot of skeptics honestly. It's a departure from her pop stuff and shows she has range.\",\n",
       " \"I wouldn't say she's overrated, but I also don't think she's the absolute best artist of our generation. Like, she’s great in her lane, but if you compare her songwriting to legends like Joni Mitchell or Carole King, it might not stack up. Still, in today's pop scene, she’s definitely one of the better ones. (There are far more overrated artists out there *cough*Drake*cough*.)\",\n",
       " 'Did you just subtly diss Drake? 😂 Leave him out of this!',\n",
       " 'Haha, nothing against Drake. Just making a point that \"overrated\" is relative. No hate to any artist.',\n",
       " \"Ugh, this argument again. If you don't like her music, just don't listen to it. Why spend energy tearing her down? Let people enjoy things. We go through this cycle every time she releases something or wins an award. It's getting old.\",\n",
       " \"I'm posting here because she's everywhere and it's frustrating. This is a discussion forum, so I'm discussing. People are allowed to express dislike just as others express love. If it's old for you, you can ignore it too.\",\n",
       " 'Overrated is putting it lightly. The masses just have low standards nowadays. Give them a catchy hook and some gossip, and they call it art. Try listening to real musicians sometime – people who write complex music or play actual instruments at a virtuoso level. Pop music like hers is fast-food for the ears.',\n",
       " 'Alright, we get it, you\\'re very sophisticated. Let people enjoy their \"fast-food\" music if it makes them happy. Not everything has to be a Mozart piece to have value. Different music serves different purposes.',\n",
       " \"Sure, enjoy whatever. Just don't act like it's on the same level as the greats. That’s my gripe – people treating her like she's the second coming of music Jesus or something.\",\n",
       " 'OP, you need to calm down. 😉 (See what I did there?) Bold move posting this, though – *grabs popcorn* 🍿 this is gonna be good.',\n",
       " \"Hahaha pass the popcorn, I'm here for the show too!\",\n",
       " 'You can call her overrated, but for me, her music has been life-changing. Her lyrics got me through some really tough times. Maybe she’s not for everyone, but dismissing her as \"overrated\" kinda ignores the genuine impact she has on millions of people. That connection and comfort her songs provide – you can\\'t put an overrated/underrated label on that.',\n",
       " \"I’m happy her music helped you, but the impact on listeners doesn’t automatically mean the artist is objectively great. It’s awesome she connects with fans, but some of us just don't see anything special in the music itself.\",\n",
       " \"Her popularity is more about her personal drama than her music. Every time she dates someone or breaks up, it turns into an album and marketing frenzy. It feels like a soap opera. Without that spotlight on her personal life, I doubt she'd be as huge. It's not about the art, it's about the celebrity.\",\n",
       " \"Plenty of artists use personal experiences in their music – that’s what songwriting often is. Why single her out for it? And her fame isn't just tabloids; her fans genuinely connect to her songs. The media might hype her relationships, but her staying power comes from her music resonating with people.\",\n",
       " 'I get that others do it too, but with her it feels like a formula: do something in her personal life, then write a song about it and watch the publicity roll in. It works, sure, but it makes the music feel less genuine to me.',\n",
       " \"Finally someone said it. I've always thought her music is shallow and formulaic. She’s basically a product crafted by the industry. People act like she’s a lyrical genius, but her lyrics are basic and repetitive. There are so many artists out there with more originality who don't get a fraction of the attention she gets. It's frustrating.\",\n",
       " 'Calling her a \"product\" is unfair. She started writing songs as a teenager. Sure, she\\'s hugely popular, but she hustled for that. Dismissing her lyrics as basic ignores songs like \"All Too Well\" that many consider brilliant songwriting. You can prefer other artists, but that doesn’t mean she lacks talent.',\n",
       " 'If \"All Too Well\" is what passes for brilliant these days, my point stands. It\\'s a decent breakup song, not some masterpiece. She got big because of a mix of talent and massive marketing. Plenty of artists have that combo, she’s just the lucky one at the top.',\n",
       " \"I wouldn't call her overrated. I'm not a Swiftie, but I enjoy some of her songs. She’s clearly talented in songwriting and connecting with her audience. Maybe she's overexposed (you hear her songs everywhere), but that’s different than overrated. It just means a lot of people like her work. To each their own, I guess.\",\n",
       " \"Agreed. Overexposed, maybe. Overrated, no. There's a difference.\",\n",
       " 'I disagree that she\\'s overrated. Her songwriting has evolved significantly over the years. Compare her album \"Speak Now\" to \"Folklore\" – you can see growth and range. Overrated implies she\\'s given undue praise, but critics and fans alike have reasons for lauding her (e.g., lyricism, reinventing her sound, live performances). It’s fine if you don’t enjoy her music, but that doesn’t mean her acclaim isn’t earned.',\n",
       " \"I still find her music average, regardless of growth. She might write her songs, but that doesn't automatically make them great. Critics can be biased or jump on bandwagons too.\",\n",
       " 'Exactly. People throw around \"overrated\" too easily. There\\'s concrete evidence of her talent (like songwriting credits and positive reviews). You can say \"not my taste\" but overrated? Nah.',\n",
       " 'Overrated? Seriously? Taylor Swift writes her own songs, plays instruments, and puts on amazing shows. There\\'s a reason she has millions of fans and a bunch of awards. This take just sounds like jealousy or ignorance. You might not like her, but calling her \"overrated\" is just wrong.',\n",
       " \"I'm not jealous, I just don't think hype equals quality. Sure she has awards, but awards don't automatically mean someone's the best. I'm allowed to not be impressed by her, chill.\",\n",
       " 'You\\'re allowed your opinion, but calling her success just \"hype\" is disrespectful. If it was all hype, she wouldn\\'t last over a decade in the industry. Maybe give her music a real chance instead of dismissing it.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, OP, Imma let you finish, but Beyoncé had one of the best videos of all time! *Of all time!* 😏 0.9864674\n"
     ]
    }
   ],
   "source": [
    "for index, value in enumerate(senti):\n",
    "    if value[2] > 0.96 and value[2] < 0.9999:\n",
    "        print(text[index], value[2])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864674"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([s[2] for s in senti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus, minus, zero = 0, 0, 0\n",
    "\n",
    "for neg, neu, pos in senti:\n",
    "    if neg > 0.69:\n",
    "        minus += 1\n",
    "    elif pos > 0.69:\n",
    "        plus += 1\n",
    "    else:\n",
    "        zero += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 39 10\n"
     ]
    }
   ],
   "source": [
    "print(minus, zero, plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polarity(tweet_data):\n",
    "    stack = tweet_data['comments']\n",
    "    visited = set()\n",
    "    responses = []\n",
    "    while stack:\n",
    "        tweet = stack.pop()\n",
    "        visited.add(tweet['message_id'])\n",
    "        responses.append(tweet['comment_text'])\n",
    "        if 'replies' not in tweet.keys():\n",
    "            continue\n",
    "        for new_tweet in tweet['replies']:\n",
    "            if new_tweet['message_id'] not in visited:\n",
    "                stack.append(new_tweet)\n",
    "\n",
    "    senti = []\n",
    "    text = []\n",
    "    for resp in responses:\n",
    "        text.append(resp)\n",
    "        senti.append(tweet_sentiment(resp))\n",
    "    \n",
    "    plus, minus, zero = 0, 0, 0\n",
    "\n",
    "    for neg, neu, pos in senti:\n",
    "        if neg > 0.69:\n",
    "            minus += 1\n",
    "        elif pos > 0.69:\n",
    "            plus += 1\n",
    "        else:\n",
    "            zero += 1\n",
    "    \n",
    "    return ((minus + plus) / max(zero, 0.001)) * (plus + minus + zero)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polarity(tweet_data):\n",
    "    stack = tweet_data['comments']\n",
    "    visited = set()\n",
    "    responses = []\n",
    "    while stack:\n",
    "        tweet = stack.pop()\n",
    "        visited.add(tweet['message_id'])\n",
    "        responses.append(tweet['comment_text'])\n",
    "        if 'replies' not in tweet.keys():\n",
    "            continue\n",
    "        for new_tweet in tweet['replies']:\n",
    "            if new_tweet['message_id'] not in visited:\n",
    "                stack.append(new_tweet)\n",
    "\n",
    "    senti = []\n",
    "    text = []\n",
    "    for resp in responses:\n",
    "        text.append(resp)\n",
    "        senti.append(tweet_sentiment(resp))\n",
    "    \n",
    "    plus, minus, zero = 0, 0, 0\n",
    "\n",
    "    for neg, neu, pos in senti:\n",
    "        if neg > 0.69:\n",
    "            minus += 1\n",
    "        elif pos > 0.69:\n",
    "            plus += 1\n",
    "        else:\n",
    "            zero += 1\n",
    "    \n",
    "    return ((minus + plus) / max(zero, 0.001)) * (plus + minus + zero)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent(name, personality, sentiment, sign):\n",
    "    return {\n",
    "        \"name\" : name,\n",
    "        \"personality\" : personality,\n",
    "        \"sentiment\" : sentiment,\n",
    "        \"sign\": sign\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parallel(tweet_data):\n",
    "    # formatting\n",
    "    return_template = { # agent 1, agent 2, ... \n",
    "        \"agents\": [\n",
    "\n",
    "        ]\n",
    "    }\n",
    "    agent_personalities = {}\n",
    "    agent_sentiments = {} # agent 47 : [0.84, 0.99, 0.75]\n",
    "    agent_sign = {} # agent 47 : [pos, neg, neu]\n",
    "\n",
    "    stack = tweet_data['comments']\n",
    "    visited = set()\n",
    "    responses = []\n",
    "    while stack:\n",
    "        # examining current tweet\n",
    "        tweet = stack.pop()\n",
    "        visited.add(tweet['message_id'])\n",
    "\n",
    "        # processing tweet\n",
    "        author = tweet['author_name']\n",
    "        if agent_personalities.get(author, None) == None: # note: need to standardize\n",
    "            agent_personalities[author] = tweet['personality']\n",
    "\n",
    "        neg, neu, pos = tweet_sentiment(tweet['comment_text'])\n",
    "\n",
    "        if neg > neu and neg > pos: # neg\n",
    "            agent_sign[author] = agent_sign.get(author, []) + [\"negative\"]\n",
    "        elif pos > neu and pos > neg: # pos\n",
    "            agent_sign[author] = agent_sign.get(author, []) + [\"positive\"]\n",
    "        else:\n",
    "            agent_sign[author] = agent_sign.get(author, []) + [\"neutral\"]\n",
    "        \n",
    "        agent_sentiments[author] = max(neg, neu, pos)\n",
    "\n",
    "\n",
    "        # finding new tweets\n",
    "        if 'replies' not in tweet.keys():\n",
    "            continue\n",
    "        for new_tweet in tweet['replies']:\n",
    "            if new_tweet['message_id'] not in visited:\n",
    "                stack.append(new_tweet)\n",
    "    \n",
    "    for author in agent_personalities.keys():\n",
    "        return_template['agents'].append(make_agent(author, agent_personalities[author], agent_sentiments[author], agent_sign[author]))\n",
    "\n",
    "    #schema = json.dump(return_template)\n",
    "    # return schema\n",
    "    return return_template\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = calculate_parallel(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Agent 1',\n",
       " 'personality': {'Sarcastic': 0.12,\n",
       "  'Anger': -0.85,\n",
       "  'Neuroticism': 0.25,\n",
       "  'Toxcitiy': -0.12,\n",
       "  'Obsession': 0.3,\n",
       "  'Elitism': 0,\n",
       "  'Sycophantic': 0.4,\n",
       "  'Loyalty': 0.9,\n",
       "  'Apathy': 0.0},\n",
       " 'sentiment': 0.98331636,\n",
       " 'sign': ['positive']}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['agents'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pi(tweet_data, temp=0.69):\n",
    "    stack = tweet_data['comments']\n",
    "    visited = set()\n",
    "    responses = []\n",
    "    while stack:\n",
    "        tweet = stack.pop()\n",
    "        visited.add(tweet['message_id'])\n",
    "        responses.append(tweet['comment_text'])\n",
    "        for new_tweet in tweet['replies']:\n",
    "            if new_tweet['message_id'] not in visited:\n",
    "                stack.append(new_tweet)\n",
    "    senti = []\n",
    "    for resp in responses:\n",
    "        senti.append(tweet_sentiment(resp))\n",
    "    \n",
    "    plus, minus, zero = 0, 0, 0\n",
    "\n",
    "    for neg, neu, pos in senti:\n",
    "        if neg > temp:\n",
    "            minus += 1\n",
    "        elif pos > temp:\n",
    "            plus += 1\n",
    "        else:\n",
    "            zero += 1\n",
    "        \n",
    "    schema = {\n",
    "        \"sentiment_counts\": {\n",
    "            \"positive\" : plus,\n",
    "            \"negative\" : minus,\n",
    "            \"neutral\" : zero\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return schema\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment_counts': {'positive': 0, 'negative': 0, 'neutral': 0}}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_pi(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample stop words: [\"you've\", 'over', 'off', 'with', 'each', 'before', 'where', 'do', 'in', 'again']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"Sample stop words:\", list(stop_words)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def get_word_frequencies_json(sentences):\n",
    "    word_freq = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize into input IDs\n",
    "        input_ids = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        word = \"\"\n",
    "        for token in tokens:\n",
    "            if token.startswith(\"##\"):\n",
    "                word += token[2:]  # Continue the subword\n",
    "            else:\n",
    "                if word:  # Add the previous word if exists\n",
    "                    word_lower = word.lower()\n",
    "                    if word_lower not in stop_words and word_lower.isalpha():\n",
    "                        word_freq[word_lower] = word_freq.get(word_lower, 0) + 1\n",
    "                word = token  # Start a new word\n",
    "\n",
    "        # Catch the last word\n",
    "        if word:\n",
    "            word_lower = word.lower()\n",
    "            if word_lower not in stop_words and word_lower.isalpha():\n",
    "                word_freq[word_lower] = word_freq.get(word_lower, 0) + 1\n",
    "\n",
    "    # Convert to JSON format\n",
    "    word_frequencies = [{\"text\": word, \"value\": count} for word, count in word_freq.items()]\n",
    "    # return json.dumps({\"word_frequencies\": word_frequencies}, indent=2)\n",
    "    return {\"word_frequencies\": word_frequencies}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cloud(tweet_data, temp=0.69):\n",
    "    stack = tweet_data['comments']\n",
    "    visited = set()\n",
    "    responses = []\n",
    "    while stack:\n",
    "        tweet = stack.pop()\n",
    "        visited.add(tweet['message_id'])\n",
    "        responses.append(tweet['comment_text'])\n",
    "        for new_tweet in tweet['replies']:\n",
    "            if new_tweet['message_id'] not in visited:\n",
    "                stack.append(new_tweet)\n",
    "\n",
    "    return get_word_frequencies_json(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = calculate_cloud(tweet_data)\n",
    "\n",
    "#write to json file\n",
    "with open('several-ducks-datahacks25/agents/word_cloud_ex.json', 'w') as f:\n",
    "    json.dump(word_cloud, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agents': [{'name': 'Agent 11',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.6060652,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 8',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.88908476,\n",
       "   'sign': ['neutral', 'neutral']},\n",
       "  {'name': 'Agent 9',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.85243106,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 10',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.8895737,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 5',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.7713573,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 6',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.52467805,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 7',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.5327768,\n",
       "   'sign': ['positive']},\n",
       "  {'name': 'Agent 1',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.8710286,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 2',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.74493915,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 4',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.8457421,\n",
       "   'sign': ['neutral']},\n",
       "  {'name': 'Agent 3',\n",
       "   'personality': {'Sarcastic': 0.12,\n",
       "    'Anger': -0.85,\n",
       "    'Neuroticism': 0.25,\n",
       "    'Toxcitiy': -0.12,\n",
       "    'Obsession': 0.3,\n",
       "    'Elitism': 0,\n",
       "    'Sycophantic': 0.4,\n",
       "    'Loyalty': 0.9,\n",
       "    'Apathy': 0.0},\n",
       "   'sentiment': 0.6032835,\n",
       "   'sign': ['neutral']}]}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)\n",
    "\n",
    "calculate_parallel(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word_frequencies': [{'text': 'love', 'value': 1},\n",
       "  {'text': 'hate', 'value': 1},\n",
       "  {'text': 'need', 'value': 1},\n",
       "  {'text': 'chill', 'value': 1},\n",
       "  {'text': 'really', 'value': 1},\n",
       "  {'text': 'acting', 'value': 1},\n",
       "  {'text': 'like', 'value': 3},\n",
       "  {'text': 'invented', 'value': 1},\n",
       "  {'text': 'music', 'value': 1},\n",
       "  {'text': 'calm', 'value': 1},\n",
       "  {'text': 'nobody', 'value': 1},\n",
       "  {'text': 'said', 'value': 1},\n",
       "  {'text': 'vibing', 'value': 1},\n",
       "  {'text': 'let', 'value': 1},\n",
       "  {'text': 'us', 'value': 2},\n",
       "  {'text': 'live', 'value': 1},\n",
       "  {'text': 'feed', 'value': 2},\n",
       "  {'text': 'full', 'value': 2},\n",
       "  {'text': 'swift', 'value': 2},\n",
       "  {'text': 'relevant', 'value': 1},\n",
       "  {'text': 'obsessed', 'value': 1},\n",
       "  {'text': 'vibe', 'value': 1},\n",
       "  {'text': 'somewhere', 'value': 1},\n",
       "  {'text': 'else', 'value': 1},\n",
       "  {'text': 'right', 'value': 1},\n",
       "  {'text': 'whether', 'value': 1},\n",
       "  {'text': 'ability', 'value': 1},\n",
       "  {'text': 'reinvent', 'value': 1},\n",
       "  {'text': 'impressive', 'value': 1},\n",
       "  {'text': 'maybe', 'value': 1},\n",
       "  {'text': 'marketing', 'value': 1},\n",
       "  {'text': 'gimmicks', 'value': 1},\n",
       "  {'text': 'lol', 'value': 1},\n",
       "  {'text': 'tell', 'value': 1},\n",
       "  {'text': 'understand', 'value': 1},\n",
       "  {'text': 'artistic', 'value': 1},\n",
       "  {'text': 'evolution', 'value': 1},\n",
       "  {'text': 'without', 'value': 1},\n",
       "  {'text': 'telling', 'value': 1},\n",
       "  {'text': 'literally', 'value': 1},\n",
       "  {'text': 'best', 'value': 1},\n",
       "  {'text': 'songwriter', 'value': 1},\n",
       "  {'text': 'generation', 'value': 1},\n",
       "  {'text': 'period', 'value': 1},\n",
       "  {'text': 'overrated', 'value': 1},\n",
       "  {'text': 'lyrics', 'value': 1},\n",
       "  {'text': 'high', 'value': 1},\n",
       "  {'text': 'school', 'value': 1},\n",
       "  {'text': 'poetry', 'value': 1},\n",
       "  {'text': 'go', 'value': 1},\n",
       "  {'text': 'back', 'value': 1},\n",
       "  {'text': 'metal', 'value': 1},\n",
       "  {'text': 'cave', 'value': 1},\n",
       "  {'text': 'leave', 'value': 1},\n",
       "  {'text': 'peace', 'value': 1},\n",
       "  {'text': 'clearly', 'value': 1},\n",
       "  {'text': 'listened', 'value': 1},\n",
       "  {'text': 'well', 'value': 1},\n",
       "  {'text': 'minute', 'value': 1},\n",
       "  {'text': 'version', 'value': 1}]}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)\n",
    "\n",
    "calculate_pi(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word_frequencies': [{'text': 'love', 'value': 1},\n",
       "  {'text': 'hate', 'value': 1},\n",
       "  {'text': 'need', 'value': 1},\n",
       "  {'text': 'chill', 'value': 1},\n",
       "  {'text': 'really', 'value': 1},\n",
       "  {'text': 'acting', 'value': 1},\n",
       "  {'text': 'like', 'value': 3},\n",
       "  {'text': 'invented', 'value': 1},\n",
       "  {'text': 'music', 'value': 1},\n",
       "  {'text': 'calm', 'value': 1},\n",
       "  {'text': 'nobody', 'value': 1},\n",
       "  {'text': 'said', 'value': 1},\n",
       "  {'text': 'vibing', 'value': 1},\n",
       "  {'text': 'let', 'value': 1},\n",
       "  {'text': 'us', 'value': 2},\n",
       "  {'text': 'live', 'value': 1},\n",
       "  {'text': 'feed', 'value': 2},\n",
       "  {'text': 'full', 'value': 2},\n",
       "  {'text': 'swift', 'value': 2},\n",
       "  {'text': 'relevant', 'value': 1},\n",
       "  {'text': 'obsessed', 'value': 1},\n",
       "  {'text': 'vibe', 'value': 1},\n",
       "  {'text': 'somewhere', 'value': 1},\n",
       "  {'text': 'else', 'value': 1},\n",
       "  {'text': 'right', 'value': 1},\n",
       "  {'text': 'whether', 'value': 1},\n",
       "  {'text': 'ability', 'value': 1},\n",
       "  {'text': 'reinvent', 'value': 1},\n",
       "  {'text': 'impressive', 'value': 1},\n",
       "  {'text': 'maybe', 'value': 1},\n",
       "  {'text': 'marketing', 'value': 1},\n",
       "  {'text': 'gimmicks', 'value': 1},\n",
       "  {'text': 'lol', 'value': 1},\n",
       "  {'text': 'tell', 'value': 1},\n",
       "  {'text': 'understand', 'value': 1},\n",
       "  {'text': 'artistic', 'value': 1},\n",
       "  {'text': 'evolution', 'value': 1},\n",
       "  {'text': 'without', 'value': 1},\n",
       "  {'text': 'telling', 'value': 1},\n",
       "  {'text': 'literally', 'value': 1},\n",
       "  {'text': 'best', 'value': 1},\n",
       "  {'text': 'songwriter', 'value': 1},\n",
       "  {'text': 'generation', 'value': 1},\n",
       "  {'text': 'period', 'value': 1},\n",
       "  {'text': 'overrated', 'value': 1},\n",
       "  {'text': 'lyrics', 'value': 1},\n",
       "  {'text': 'high', 'value': 1},\n",
       "  {'text': 'school', 'value': 1},\n",
       "  {'text': 'poetry', 'value': 1},\n",
       "  {'text': 'go', 'value': 1},\n",
       "  {'text': 'back', 'value': 1},\n",
       "  {'text': 'metal', 'value': 1},\n",
       "  {'text': 'cave', 'value': 1},\n",
       "  {'text': 'leave', 'value': 1},\n",
       "  {'text': 'peace', 'value': 1},\n",
       "  {'text': 'clearly', 'value': 1},\n",
       "  {'text': 'listened', 'value': 1},\n",
       "  {'text': 'well', 'value': 1},\n",
       "  {'text': 'minute', 'value': 1},\n",
       "  {'text': 'version', 'value': 1}]}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('several-ducks-datahacks25/agents/sample_msg.json', 'r') as f:\n",
    "        tweet_data = json.load(f)\n",
    "\n",
    "calculate_cloud(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roberta-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
